---
title: Machine Analysis of Data for Human Audition and Visualization
layout: homelay
permalink: /
---

The Machine Analysis of Data for Human Audition and Visualization (MADHAV) Lab  is a research group in the [Department of Electrical Engineering](https://iitk.ac.in/ee) at the [Indian Institute of Technology Kanpur](https://iitk.ac.in)

## About
Our groupâ€™s research interests lie at the intersection of the theory and application of machine learning - with a focus on applications in audio and speech processing, and Physics. With a strong interest in the mathematical fundamentals and a passion for real-world application, our group aims on being at the forefront of the field, by carrying out impactful research in the areas of deep learning, machine learning and speech processing, guided by application contexts derived from real-world use.

  - Machine learning for audio signal processing
      - audio retrieval: representation learning
      - speech recognition: confidence estimation
      - music analysis: explainable AI and domain adaptation
  - Generative Machine learning
      - Normalizing flows, adversarial learning, Monte Carlo, application in Physics (lattice QCD and statistical physics)
  - Time series analysis on sensor data
      - domain adaptation, semi-supervised learning

## News

<!-- We in MADHAV Lab have been involved with many sponsored projects over the years (IMPRINT, Samsung) resulting into valuable contributions to the audio/speech processing community.
A number of our current projects are funded by Prasar Bharati, NLTM, DST, Maharashtra Pollution Control Board, SPARC, Google AI. We have collaborated with several leading institutions including ETH Zurich, MIT, La Trobe Universtiy. We are always looking forward to exciting corporate or academic collaborations. -->

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
    <!-- <a id="news"><h2>News</h2></a> -->
    <p>
    <div style="width:100%;overflow-y:scroll; height:230px;"><!--230px-->
        <ul id="news">
            <li><b>Jan 2023</b>: One <a href="https://openreview.net/forum?id=v8Mi8KU6056" target="_blank">paper</a> on audio representation learning accepted at the ICLR' 23. Congratulations Adhiraj!</li>
            <li><b>Jan 2023</b>: Kavya and Prof. Vipul delivered a <a href="https://dl.acm.org/doi/abs/10.1145/3570991.3571030" target="_blank">tutorial</a> on Meta Learning at the CODS-COMAD' 23 at IIT Bombay.</li>
            <li><b>Nov 2022</b>: One <a href="https://ismir2022program.ismir.net/poster_100.html" target="_blank">paper</a> on Audio Fingerprinting accepted at the ISMIR' 22. Congratulations Anup!</li>
            <li><b>Oct 2022</b>: Prof. Vipul delivered a <a href="http://c4dm.eecs.qmul.ac.uk/news/news.2022-10-11.C4DM_Seminar_-_Vipul_Arora_-_Model_Adaptation_for_Learning_from_Small_Data.html" target="_blank">talk</a> on Model Adaptation for Learning from Small Data at C4DM, Queen Mary University of London.</li>
        </ul>
    </div>
    </p>
    </tr>
</tbody></table>
